---
title: '3\. Worksheet: Basic R'
author: 'Student Name; Z620: Quantitative Biodiversity, Indiana University'
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    df_print: paged
geometry: margin=2.54cm
---

## OVERVIEW

This worksheet introduces some of the basic features of the R computing environment (http://www.r-project.org).
It is designed to be used along side the **3. RStudio** handout in your binder. 
You will not be able to complete the exercises without the corresponding handout.

## Directions:
1. In the Markdown version of this document in your cloned repo, change "Student Name" on line 3 (above) with your name.
2. Complete as much of the worksheet as possible during class.
3. Use the handout as a guide; it contains a more complete description of data sets along with examples of proper scripting needed to carry out the exercises.
4. Answer questions in the  worksheet.
Space for your answers is provided in this document and is indicated by the ">" character.
If you need a second paragraph be sure to start the first line with ">".
You should notice that the answer is highlighted in green by RStudio (color may vary if you changed the editor theme). 
5. Before you leave the classroom today, you must **push** this file to your GitHub repo, at whatever stage you are. This will enable you to pull your work onto your own computer.
6. When you have completed the worksheet, **Knit** the text and code into a single PDF file by pressing the `Knit` button in the RStudio scripting panel.
This will save the PDF output in your '3.RStudio' folder.
7. After Knitting, please submit the worksheet by making a **push** to your GitHub repo and then create a **pull request** via GitHub.
Your pull request should include this file (**3.RStudio_Worksheet.Rmd**) with all code blocks filled out and questions answered) and the PDF output of `Knitr`   
(**3.RStudio_Worksheet.pdf**).

The completed exercise is due on **Wednesday, January 22^nd^, 2025 before 12:00 PM (noon)**.

## 1) HOW WE WILL BE USING R AND OTHER TOOLS

You are working in an RMarkdown (.Rmd) file.
This allows you to integrate text and R code into a single document.
There are two major features to this document: 1) Markdown formatted text and 2) "chunks" of R code.
Anything in an R code chunk will be interpreted by R when you *Knit* the document.

When you are done, you will *knit* your document together.
However, if there are errors in the R code contained in your Markdown document, you will not be able to knit a PDF file. 
If this happens, you will need to review your code, locate the source of the error(s), and make the appropriate changes.
Even if you are able to knit without issue, you should review the knitted document for correctness and completeness before you submit the Worksheet. Next to the `Knit` button in the RStudio scripting panel there is a spell checker button (`ABC`) button.

## 2) SETTING YOUR WORKING DIRECTORY

In the R code chunk below, please provide the code to: 
1) clear your R environment,
2) print your current working directory, and
3) set your working directory to your '3.RStudio' folder. 

```{r}



## Clear the R environment
rm(list = ls())

### Print working directory
getwd()

##set working directory
setwd("C:/Users/ADMIN/OneDrive/Documents/GitHub/QB2025_Nambiar/Week1-RStudio/data")  
```

## 3) USING R AS A CALCULATOR

To follow up on the pre-class exercises, please calculate the following in the R code chunk below. 
Feel free to reference the **1. Introduction to version control and computing tools** handout. 

1) the volume of a cube with length, l, = 5 (volume = l^3 )
2) the area of a circle with radius, r, = 2 (area = pi * r^2). 
3) the length of the opposite side of a right-triangle given that the angle, theta, = pi/4. (radians, a.k.a. 45Â°) and with hypotenuse length sqrt(2) (remember: sin(theta) = opposite/hypotenuse).
4) the log (base e) of your favorite number.

```{r}

### Volume of  cube 
l <- 5
volume_cube <- l^3
volume_cube

# #Area of a circle 
r <- 2
area_circle <- pi * r^2
area_circle

# Length of the opposite side of  right-triangle
theta <- pi / 4  # unit-readians
hypotenuse <- sqrt(2)
opposite_length <- sin(theta) * hypotenuse
opposite_length

# Log (base e) of my favorite number (n)
n <- 9  
log_n <- log(n)
log_n





```

## 4) WORKING WITH VECTORS

To follow up on the pre-class exercises, please perform the requested operations in the R-code chunks below.

### Basic Features Of Vectors

In the R-code chunk below, do the following: 
1) Create a vector `x` consisting of any five numbers.
2) Create a new vector `w` by multiplying `x` by 14 (i.e., "scalar").
3) Add `x` and `w` and divide by 15.

```{r}

#random numbers within a limit
x<-sample(2:30, 5)
x

w<-14*x
w

final<-(x + w)/15
final

```

Now, do the following: 
1) Create another vector (`k`) that is the same length as `w`.
2) Multiply `k` by `x`.
3) Use the combine function to create one more vector, `d` that consists of any three elements from `w` and any four elements of `k`.

```{r}
k<-sample(47:99, 5)
k

mult<-k*x
mult

d <- c(sample(w, 3), sample(k, 4))
d

```

### Summary Statistics of Vectors

In the R-code chunk below, calculate the **summary statistics** (i.e., maximum, minimum, sum, mean, median, variance, standard deviation, and standard error of the mean) for the vector (`v`) provided.

```{r}
v <- c(16.4, 16.0, 10.1, 16.8, 20.5, NA, 20.2, 13.1, 24.8, 20.2, 25.0, 20.5, 30.5, 31.4, 27.1)

summary(v)

#variance

var(x)

#standard deviation

sd(x)
#create function
se <- function(x) {
  sd_x <- sd(x)#standard deviation
  #number of observations
  n <- length(x)
  # Standard error
  se <- sd_x / sqrt(n)
  return(se)
}
  
se(x)







```

## 5) WORKING WITH MATRICES

In the R-code chunk below, do the following:
Using a mixture of Approach 1 and 2 from the **3. RStudio** handout, create a matrix with two columns and five rows.
Both columns should consist of random numbers.
Make the mean of the first column equal to 8 with a standard deviation of 2 and the mean of the second column equal to 25 with a standard deviation of 10.

```{r}
x<-rnorm(5, mean=8, sd=2)
y<-rnorm (5, mean=5, sd=10)
x
y

dataframe<-data.frame(x,y)
dataframe
```

***Question 1***: What does the `rnorm` function do? 
What do the arguments in this function specify? 
Remember to use `help()` or type `?rnorm`.

> Answer 1: "rnorm" is a function generate random numbers of a specific length which can be loaded as a vector of a specific length, mean and standard deviation. Most importantly this data will be nroamlly distributed


In the R code chunk below, do the following: 
1) Load `matrix.txt` from the **3.RStudio** data folder as matrix `m`.
2) Transpose this matrix.
3) Determine the dimensions of the transposed matrix.

```{r}
m<-read.table("C:/Users/ADMIN/OneDrive/Documents/GitHub/QB2025_Nambiar/Week1-RStudio/data/matrix.txt", sep = "\t", header = TRUE)
m
#transposed matrix

m_trans<-t(m)
m

#dimensions

dim(m_trans)

```


***Question 2***: What are the dimensions of the matrix you just transposed?

> Answer 2:5 rows and 9 columns


###Indexing a Matrix

In the R code chunk below, do the following:
1) Index matrix `m` by selecting all but the third column.
2) Remove the last row of matrix `m`.

```{r}
m1<-m[,-3] #remove column 3

m2<-m[-9,]
m2

```

## 6) BASIC DATA VISUALIZATION AND STATISTICAL ANALYSIS
### Load Zooplankton Data Set

In the R code chunk below, do the following:
1) Load the zooplankton data set from the **3.RStudio** data folder.
2) Display the structure of this data set.

```{r}
zoops<-read.table("C:/Users/ADMIN/OneDrive/Documents/GitHub/QB2025_Nambiar/Week1-RStudio/data/zoop_nuts.txt", sep = "\t", header = TRUE)
zoops
str(zoops) #structure
```

### Correlation

In the R-code chunk below, do the following:
1) Create a matrix with the numerical data in the `zoop` dataframe.
2) Visualize the pairwise **bi-plots** of the numerical variables.
3) Conduct a simple **Pearson's correlation** analysis.

```{r}
zoop1<-as.data.frame(zoops[,-(1:2)])
zoop1
zoops
pairs(zoop1) #pairwise plots

cor_mat<- cor(zoop1, method = "pearson")
cor_mat

```


***Question 3***: Describe some of the general features based on the visualization and correlation analysis above?

> Answer 3: I have calculated an extra column mean_bio which is the mean biomass of all the species ina  tank (row). CHYD seems to have the strongest correlation with the mean_bio suggesting that most the mean value is determinedby CHYD. Overall, we can see the pairwise correlations of the different species of zooplanktons.


In the R code chunk below, do the following:
1) Redo the correlation analysis using the `corr.test()` function in the `psych` package with the following options: method = "pearson", adjust = "BH".
2) Now, redo this correlation analysis using a non-parametric method.
3) Use the print command from the handout to see the results of each correlation analysis.

```{r}
library(psych)


zoop1_para <- corr.test(zoop1, method = "pearson", adjust = "BH")
zoop1_para


zoop1_nonpara<-corr.test(zoop1, method = "spearman", adjust = "BH") #using spearman for the non para test
zoop1_nonpara
```

***Question 4***: 
Describe what you learned from `corr.test`. 
Specifically, are the results sensitive to whether you use parametric (i.e., Pearson's) or non-parametric methods?
When should one use non-parametric methods instead of parametric methods?
With the Pearson's method, is there evidence for false discovery rate due to multiple comparisons? 
Why is false discovery rate important?

> Answer 4: With non-parametric tests we appear to see similar result in terms of the directions of the trends but the strength of correlation is stronger in the spearman test vs pearson test (parametric). Parametric tests are used when the variables arenormally distributed, numerical adn linear (along with homoskedasticity), if these requirements are not satisfied we used non parametrics statistics. We also use non parametric statistics when we need to analyse ordinal data. Im not very clear about the relationship between Pearosn corelations and false discovery rates. 

### Linear Regression

In the R code chunk below, do the following:
1) Conduct a linear regression analysis to test the relationship between total nitrogen (TN) and zooplankton biomass (ZP).
2) Examine the output of the regression analysis.
3) Produce a plot of this regression analysis including the following: categorically labeled points, the predicted regression line with 95% confidence intervals, and the appropriate axis labels.

```{r}
library(tidyverse)

zoops<-read.table("C:/Users/ADMIN/OneDrive/Documents/GitHub/QB2025_Nambiar/Week1-RStudio/data/zoop_nuts.txt", sep = "\t", header = TRUE)

lm_model <- lm(ZP ~ TN, data = zoops)

summary(lm_model)

ggplot(zoops, aes(x = TN, y = ZP)) +
  geom_point(aes(color = factor(TN)), size = 3) +  # Points with categorical labels by TN
  geom_smooth(method = "lm", se = TRUE, color = "red", fill = "blue", alpha = 0.2) +  # Regression line with 95% CI
  labs(title = " Zooplankton Biomass (ZP) vs Total Nitrogen (TN)",
       x = "Total Nitrogen (TN)",
       y = "Zooplankton Biomass (ZP)") +
  theme_minimal() +
  theme(legend.position = "none")



```

***Question 5***: Interpret the results from the regression model

> Answer 5: Based on the output and figure we see that the interescept is at 0.69 (non-seignficant) and the slope is 0.0012(significant becuase p<0.05). This means that increase in 1 unit of TN there is increase in 0.0013 units increase in the total biomass. 




### Analysis of Variance (ANOVA)

Using the R code chunk below, do the following:
1) Order the nutrient treatments from low to high (see handout).
2) Produce a barplot to visualize zooplankton biomass in each nutrient treatment.
3) Include error bars (+/- 1 sem) on your plot and label the axes appropriately.
4) Use a one-way analysis of variance (ANOVA) to test the null hypothesis that zooplankton biomass is affected by the nutrient treatment.


```{r}
zoop1<-as.data.frame(zoops)
zoop1
colnames(zoop1)

zoop_summary <- zoop1 %>%
  group_by(NUTS) %>%
  summarize(
    mean_ZP = mean(ZP, na.rm = TRUE),
    sem_ZP = se(ZP))%>%
  mutate(NUTS = factor(NUTS, levels = c("L", "M", "H")))

####----- plots

ggplot(zoop_summary, aes(x = NUTS, y = mean_ZP)) +
  geom_bar(stat = "identity", fill = "blue", color = "black", width = 0.7) +
  geom_errorbar(aes(ymin = mean_ZP - sem_ZP, ymax = mean_ZP + sem_ZP), 
                width = 0.2, color = "red") +
  labs(
    title = "Mean Zoop biomass Across Nutrient Treatments",
    x = "Nutrient Treatment",
    y = "Mean zoop biomas (with error)"
  ) +
  theme_minimal()

# One-way ANOVA
zoop_anova <- aov(ZP ~ NUTS, data = zoop1)
summary(zoop_anova)
```

## SYNTHESIS: SITE-BY-SPECIES MATRIX

In the R code chunk below, load the zoops.txt data set in your **3.RStudio** data folder.
Create a site-by-species matrix (or dataframe) that does *not* include TANK or NUTS.
The remaining columns of data refer to the biomass (Âµg/L) of different zooplankton taxa: 
  
  + CAL = calanoid copepods
  
  + DIAP = *Diaphanasoma* sp. 
  
  + CYL = cyclopoid copepods
  
  + BOSM = *Bosmina* sp.
  
  + SIMO = *Simocephallus* sp.
  
  + CERI = *Ceriodaphnia* sp.
  
  + NAUP = naupuli (immature copepod)
  
  + DLUM = *Daphnia lumholtzi*
  
  + CHYD = *Chydorus* sp. 

***Question 6***: With the visualization and statistical tools that we learned about in the **3. RStudio** handout, use the site-by-species matrix to assess whether and how different zooplankton taxa were responsible for the total biomass (ZP) response to nutrient enrichment. 
Describe what you learned below in the "Answer" section and include appropriate code in the R chunk.

```{r}
library(performance)
zoops<-read.table("C:/Users/ADMIN/OneDrive/Documents/GitHub/QB2025_Nambiar/Week1-RStudio/data/zoops.txt", sep = "\t", header = TRUE)
zoops

#get a new column for row means
zoops <- zoops %>%
  mutate(mean_bio = rowMeans(select(., CAL:CHYD), na.rm = TRUE))

zoops

zoop_nuts<-read.table("C:/Users/ADMIN/OneDrive/Documents/GitHub/QB2025_Nambiar/Week1-RStudio/data/zoop_nuts.txt", sep = "\t", header = TRUE)

zoop_nuts

merged_zoops <- left_join(zoops, zoop_nuts, by = "TANK")

merged_zoops <- merged_zoops %>%
  select(-NUTS.y) %>%     # Remove the NUTS.y column
  rename(NUTS = NUTS.x)

merged_zoops

#wranling dataset for plot
long_zoops <- merged_zoops %>%
  pivot_longer(cols = c(CAL:mean_bio, ZP), names_to = "Sp", values_to = "biomass") %>%
  mutate(NUTS = factor(NUTS, levels = c("L", "M", "H")))  # needed for proper plot
long_zoops


#lot to see difference in response to nutrient enrichment


# 
ggplot(long_zoops, aes(x = NUTS, y = biomass, fill = Sp)) +
  geom_boxplot(outlier.color = "red", outlier.shape = 16, position = position_dodge(width = 0.8)) +
  labs(
    title = "Biomass of zooplantok species across nutrient enrichment levels",
    x = "Nutrient Treatment",
    y = "Biomass",
    fill = "Sp"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
    legend.position = "bottom"  # Position the legend below
  )

#----attempt at violin plots
ggplot(long_zoops, aes(x = NUTS, y = biomass, fill = Sp)) +
  geom_violin(trim = TRUE, position = position_dodge(width = 0.8)) +  # Violin plot
  geom_boxplot(width = 0.2, position = position_dodge(width = 0.8), outlier.color = "red", alpha = 0.5) +  # Add boxplots inside violins
  labs(
    title = "Violin Plot of Zooplankton Biomass Across Nutrient Enrichment Levels",
    x = "Nutrient Treatment",
    y = "Biomass",
    fill = "Species (Sp)"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
    legend.position = "bottom"  # Position the legend below
  )

####-------Violin plot 2

ggplot(long_zoops, aes(x = NUTS, y = biomass, fill = Sp)) +
  geom_violin(trim = TRUE, position = position_dodge(width = 0.8), alpha = 0.7) +  # Violin plot
  geom_point(position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.8), size = 1.5, alpha = 0.6) +  # Add data points
  labs(
    title = "Biomass of Zooplankton Species Across Nutrient Enrichment Levels",
    x = "Nutrient Treatment",
    y = "Biomass",
    fill = "Species (Sp)"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
    legend.position = "bottom"  # Position the legend below
  )
##anova to see difference in the response of biomass to nutrient enrichmeent

anova <- aov(biomass ~ NUTS * Sp, data = long_zoops) 

summary(anova)

merged_zoops <- merged_zoops %>%
  mutate(NUTS_numeric = as.numeric(NUTS))  # L = 1, M = 2, H = 3 #already ordered

# Separate columns for correlation test
cor_data <- merged_zoops %>%
  select(NUTS_numeric, CAL:ZP)

# Perform Spearman correlation
spearman <- corr.test(cor_data, method = "spearman", adjust = "BH")
spearman

#pearson correlations

# remove unecessary data for correlations
cor_data <- merged_zoops %>%
  select(-TANK, -NUTS, -NUTS_numeric)

pearson <- corr.test(cor_data, method = "pearson", adjust = "BH")
pearson

#####-CHYD the most important species
# specific nutrient effects on biomass--TIN

ggplot(merged_zoops, aes(x = TIN, y = CHYD)) +
  geom_point(aes(color = NUTS), size = 3) +  # Scatter plot with points colored by NUTS
  geom_smooth(method = "lm", se = TRUE, color = "red", fill = "blue", alpha = 0.2) +  # Regression line with confidence interval
  labs(
    title = "CHYD vs TIN",
    x = "Total Inorganic Nitrogen (TIN)",
    y = "CHYD Biomass",
    color = "Nutrient Treatment"
  ) +
  theme_minimal()

# Fit a linear model
lm_CHYD <- lm(CHYD ~ TIN, data = merged_zoops)

check_distribution(lm_CHYD)
summary(lm_CHYD)

#####-SIMO 
# specific nutrient effects on biomass--TIN

ggplot(merged_zoops, aes(x = TIN, y = SIMO)) +
  geom_point(aes(color = NUTS), size = 3) +  # Scatter plot with points colored by NUTS
  geom_smooth(method = "lm", se = TRUE, color = "red", fill = "blue", alpha = 0.2) +  # Regression line with confidence interval
  labs(
    title = "SIMO vs TIN",
    x = "Total Inorganic Nitrogen (TIN)",
    y = "SIMO Biomass",
    color = "Nutrient Treatment"
  ) +
  theme_minimal()

# Fit a linear model
lm_SIMO<- lm(SIMO ~ TIN, data = merged_zoops)


summary(lm_SIMO)

#####-CAL 
# specific nutrient effects on biomass--TIN

ggplot(merged_zoops, aes(x = TIN, y = CAL)) +
  geom_point(aes(color = NUTS), size = 3) +  # Scatter plot with points colored by NUTS
  geom_smooth(method = "lm", se = TRUE, color = "red", fill = "blue", alpha = 0.2) +  # Regression line with confidence interval
  labs(
    title = "CAL vs TIN",
    x = "Total Inorganic Nitrogen (TIN)",
    y = "CAL Biomass",
    color = "Nutrient Treatment"
  ) +
  theme_minimal()

# Fit a linear model
lm_CAL<- lm(CAL ~ TIN, data = merged_zoops)


summary(lm_CAL)

```
> Answer 6: Through ANOVA we see that both treatment type and taxonomic identity predict biomass.  In the first figure we see that from Low to High nutrient enrichment treatments there is increase in biomass predominantly for the species "CHYD". Through the correlation matrix we see that CHYD responds most positively and strongly to nutrient enrichments for all variables. 
Since CHYD shows the most variation we can also compare CHYD biomass and how it is predicted by the nutrient TIN. We see that the nutrient TIN predicts CHYD  biomass positively ( estimate =1.311) significantly (p<0.05) while with other species it is weak, or non significant relationship for other species such as SIMO and CAL. CAL is somewhat significant since p=0.052, and has a negative response to increase in nutrient enrichment. 



## SUBMITTING YOUR WORKSHEET
Use Knitr to create a PDF of your completed **3.RStudio_Worksheet.Rmd** document, push the repo to GitHub, and create a pull request.
Please make sure your updated repo include both the PDF and RMarkdown files.

This assignment is due on **Wednesday, January 22^nd^, 2025 at 12:00 PM (noon)**.

